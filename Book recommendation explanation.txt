
### **1. Importing Required Libraries**
```python
import pandas as pd
import numpy as np
```
- **`pandas`**: For handling and processing tabular data.
- **`numpy`**: For numerical operations and array manipulations.

---

### **2. Loading the Books Dataset**
```python
books = pd.read_csv(
    "C:\\...\\BX-Books.csv",
    sep=";",
    encoding="latin-1",
    on_bad_lines="skip"
)
```
- Reads the `BX-Books.csv` dataset.
- **`sep=";"`**: Specifies the delimiter used in the file.
- **`encoding="latin-1"`**: Handles special characters in text data.
- **`on_bad_lines="skip"`**: Skips problematic rows that cannot be parsed.

---

### **3. Cleaning and Renaming the Books Data**
```python
books = books[['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher','Image-URL-L']]
books.rename(columns={
    'Book-Title': 'Title',
    'Book-Author': 'Author',
    'Year-Of-Publication': 'Year',
    'Image-URL-L': 'Image'
}, inplace=True)
```
- Selects important columns like ISBN, Title, Author, Year, Publisher, and Image.
- Renames columns to simpler names for consistency and readability.

---

### **4. Loading the Users and Ratings Datasets**
```python
users = pd.read_csv(..., sep=";", encoding="latin-1", on_bad_lines="skip")
ratings = pd.read_csv(..., sep=";", encoding="latin-1", on_bad_lines="skip")
ratings.rename(columns={'User-ID': 'user_id', 'Book-Rating': 'book_rating'}, inplace=True)
```
- Loads user and rating data.
- Renames `User-ID` to `user_id` and `Book-Rating` to `book_rating` for easier access.

---

### **5. Filtering Active Users**
```python
x = ratings['user_id'].value_counts() > 200
y = x[x].index
ratings = ratings[ratings['user_id'].isin(y)]
```
- Filters users who have rated more than 200 books:
  - **`value_counts()`**: Counts the number of ratings per user.
  - **`x[x].index`**: Extracts user IDs with more than 200 ratings.
  - **`ratings[ratings['user_id'].isin(y)]`**: Keeps only ratings from these active users.

---

### **6. Merging Ratings with Books**
```python
rwb = ratings.merge(books, on="ISBN")
```
- Merges the `ratings` and `books` datasets on the common column `ISBN` to enrich the ratings data with book details.

---

### **7. Filtering Popular Books**
```python
num_rating = rwb.groupby('Title')['book_rating'].count().reset_index()
num_rating = num_rating.rename(columns={'book_rating': 'num_of_rating'})
final_rating = rwb.merge(num_rating, on='Title')
final_rating = final_rating[final_rating['num_of_rating'] >= 50]
final_rating.drop_duplicates(['user_id', 'Title'], inplace=True)
```
- Filters books with at least 50 ratings:
  - Groups by `Title` to count ratings for each book.
  - Merges this count back into the `final_rating` dataset.
  - Retains books with `num_of_rating >= 50`.
- Removes duplicate ratings for the same user and book.

---

### **8. Creating a User-Book Matrix**
```python
book_pivot = final_rating.pivot_table(columns='user_id', index='Title', values='book_rating')
book_pivot.fillna(0, inplace=True)
```
- Creates a pivot table where:
  - Rows are books (`Title`).
  - Columns are users (`user_id`).
  - Values are the ratings.
- Fills missing values with `0`, making the matrix sparse and suitable for collaborative filtering.

---

### **9. Converting to Sparse Matrix**
```python
from scipy.sparse import csr_matrix
book_sparse = csr_matrix(book_pivot)
```
- Converts the dense matrix (`book_pivot`) to a sparse matrix format (`csr_matrix`) for memory efficiency and compatibility with machine learning algorithms.

---

### **10. Training the Nearest Neighbors Model**
```python
from sklearn.neighbors import NearestNeighbors
model = NearestNeighbors(algorithm='brute')
model.fit(book_sparse)
```
- **`NearestNeighbors`**: A machine learning algorithm that finds the nearest neighbors for a given book.
- **`algorithm='brute'`**: Brute-force search is used for simplicity and accuracy.

---

### **11. Testing Recommendations**
```python
distance, suggestion = model.kneighbors(book_pivot.iloc[237, :].values.reshape(1, -1), n_neighbors=6)
```
- Picks a specific book (at index `237`) and finds its 5 nearest neighbors (`n_neighbors=6` includes the book itself).
- **`distance`**: The similarity distances between the selected book and its neighbors.
- **`suggestion`**: Indices of the neighboring books.

---

### **12. Displaying Recommendations**
```python
for i in range(len(suggestion)):
    print(book_pivot.index[suggestion[i]])
```
- Prints the titles of books similar to the selected book.

---

### **13. Saving Artifacts**
```python
import pickle
pickle.dump(model, open(...))
pickle.dump(book_name, open(...))
pickle.dump(final_rating, open(...))
pickle.dump(book_pivot, open(...))
```
- Saves the model and data structures to `.pkl` files for future use.

---

### **14. Recommendation Function**
```python
def recommend_book(book_name):
    book_id = np.where(book_pivot.index == book_name)[0][0]
    distance, suggestion = model.kneighbors(book_pivot.iloc[book_id, :].values.reshape(1, -1), n_neighbors=6)

    for i in range(len(suggestion)):
        books = book_pivot.index[suggestion[i]]
        for j in books:
            print(j)
```
- **Inputs**: A book name.
- Finds similar books using the trained model.
- Prints recommended book titles.

---

### **15. Testing the Recommendation Function**
```python
book_name = 'A Bend in the Road'
recommend_book(book_name)
```
- Provides recommendations for the book "A Bend in the Road."

---

### **Summary**
The system uses collaborative filtering and nearest neighbors to:
1. Preprocess user and book data.
2. Create a user-book matrix.
3. Train a model to find similar books.
4. Recommend books based on user input.

